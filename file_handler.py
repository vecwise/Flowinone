import html
import json
import os
import random
import re
import sqlite3
import hashlib
import time
from collections import OrderedDict
from datetime import datetime
from pathlib import Path
from urllib.parse import quote, quote_plus, urlparse
from typing import Dict, List, Optional, Tuple
import mimetypes
import requests
import src.eagle_api as EG
from flask import abort
from config import (
    DB_route_internal,
    DB_route_external,
    CHROME_BOOKMARK_PATH,
    SPECIAL_THUMBNAIL_DOMAINS,
)


IMAGE_EXTENSIONS = {"png", "jpg", "jpeg", "gif", "webp"}
VIDEO_EXTENSIONS = {"mp4", "mov", "avi", "mkv", "webm", "m4v"}
DEFAULT_THUMBNAIL_ROUTE = "/static/default_thumbnail.svg"
DEFAULT_VIDEO_THUMBNAIL_ROUTE = "/static/default_video_thumbnail.svg"

CACHE_DATA_DIR = "data"
THUMBNAIL_CACHE_DIR = os.path.join(CACHE_DATA_DIR, "thumbnails")
THUMBNAIL_CACHE_DB = os.path.join(CACHE_DATA_DIR, "cache.db")
FOCUS_MODES_FILE = Path(CACHE_DATA_DIR) / "focus_modes.json"
_DEFAULT_FOCUS_CONFIG = {
    "default_mode": "all",
    "modes": [
        {
            "id": "all",
            "label": "å…¨éƒ¨æ›¸ç±¤",
            "description": "é¡¯ç¤ºæ‰€æœ‰ Chrome æ›¸ç±¤"
        }
    ]
}

_DEFAULT_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9"
}


def _extract_youtube_id(url):
    if not url:
        return None
    if "youtube.com/watch" in url and "v=" in url:
        return url.split("v=")[1].split("&")[0]
    if "youtu.be/" in url:
        return url.split("youtu.be/")[1].split("?")[0]
    return None


def _get_youtube_thumbnail(video_id):
    if not video_id:
        return None
    return f"https://img.youtube.com/vi/{video_id}/hqdefault.jpg"


def _fetch_page(url: str) -> Optional[str]:
    if not url:
        return None
    try:
        response = requests.get(url, timeout=6, headers=_DEFAULT_HEADERS)
        if response.status_code == 200:
            return response.text
    except requests.RequestException:
        return None
    return None


def _fetch_og_image(url):
    html_text = _fetch_page(url)
    if not html_text:
        return None
    match = re.search(
        r"<meta[^>]+property=['\"]og:image['\"][^>]*content=['\"]([^'\"]+)",
        html_text,
        re.IGNORECASE
    )
    if match:
        return html.unescape(match.group(1))
    return None


def _get_special_site_thumbnail(url):
    domain = urlparse(url).netloc.lower()
    for site in SPECIAL_THUMBNAIL_DOMAINS:
        if site in domain:
            return _fetch_og_image(url)
    return None


def _load_or_create_focus_config() -> dict:
    """
    Ensure the focus-mode configuration exists on disk and return its raw content.
    """
    try:
        FOCUS_MODES_FILE.parent.mkdir(parents=True, exist_ok=True)
    except OSError:
        # If the directory cannot be created, fall back to defaults in-memory.
        return json.loads(json.dumps(_DEFAULT_FOCUS_CONFIG))

    if not FOCUS_MODES_FILE.exists():
        try:
            FOCUS_MODES_FILE.write_text(
                json.dumps(_DEFAULT_FOCUS_CONFIG, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
        except OSError:
            return json.loads(json.dumps(_DEFAULT_FOCUS_CONFIG))
        return json.loads(json.dumps(_DEFAULT_FOCUS_CONFIG))

    try:
        return json.loads(FOCUS_MODES_FILE.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return json.loads(json.dumps(_DEFAULT_FOCUS_CONFIG))


def _sanitize_focus_config(raw_config: dict) -> Dict[str, object]:
    """
    Normalise the focus-mode configuration to a predictable structure.
    """
    modes: List[Dict[str, object]] = []
    seen: set[str] = set()

    raw_modes = raw_config.get("modes") if isinstance(raw_config, dict) else None
    if not isinstance(raw_modes, list):
        raw_modes = []

    for entry in raw_modes:
        if not isinstance(entry, dict):
            continue

        mode_id = str(entry.get("id") or "").strip()
        if not mode_id:
            continue

        mode_key = mode_id.lower()
        if mode_key in seen:
            continue

        seen.add(mode_key)

        label = entry.get("label") or mode_id
        description = entry.get("description")

        def _collect_strings(values):
            if not isinstance(values, list):
                return []
            collected = []
            for value in values:
                if isinstance(value, str):
                    stripped = value.strip()
                    if stripped:
                        collected.append(stripped)
            return collected

        keywords = _collect_strings(entry.get("keywords"))
        folders = _collect_strings(entry.get("folders"))
        include_urls = _collect_strings(entry.get("include_urls"))
        exclude_keywords = _collect_strings(entry.get("exclude_keywords"))
        exclude_urls = _collect_strings(entry.get("exclude_urls"))

        modes.append({
            "id": mode_key,
            "label": label,
            "description": description,
            "keywords": keywords,
            "keywords_lower": [value.lower() for value in keywords],
            "folders": folders,
            "folders_lower": [value.lower() for value in folders],
            "include_urls": include_urls,
            "include_urls_lower": [value.lower() for value in include_urls],
            "exclude_keywords": exclude_keywords,
            "exclude_keywords_lower": [value.lower() for value in exclude_keywords],
            "exclude_urls": exclude_urls,
            "exclude_urls_lower": [value.lower() for value in exclude_urls],
        })

    if "all" not in seen:
        modes.insert(0, {
            "id": "all",
            "label": "å…¨éƒ¨æ›¸ç±¤",
            "description": "é¡¯ç¤ºæ‰€æœ‰ Chrome æ›¸ç±¤",
            "keywords": [],
            "keywords_lower": [],
            "folders": [],
            "folders_lower": [],
            "include_urls": [],
            "include_urls_lower": [],
            "exclude_keywords": [],
            "exclude_keywords_lower": [],
            "exclude_urls": [],
            "exclude_urls_lower": [],
        })
        seen.add("all")

    default_mode_raw = raw_config.get("default_mode") if isinstance(raw_config, dict) else "all"
    default_mode = str(default_mode_raw or "all").strip().lower()
    if default_mode not in seen:
        default_mode = "all"

    return {
        "default_mode": default_mode,
        "modes": modes
    }


def _get_focus_mode_config() -> Dict[str, object]:
    """
    Return the normalised focus-mode configuration.
    """
    raw_config = _load_or_create_focus_config()
    return _sanitize_focus_config(raw_config)


def _build_focus_matcher(mode: Dict[str, object]):
    """
    Build a predicate that checks whether a bookmark matches the supplied focus mode.
    """
    keywords = mode.get("keywords_lower", []) or []
    folder_terms = mode.get("folders_lower", []) or []
    include_urls = mode.get("include_urls_lower", []) or []
    exclude_keywords = mode.get("exclude_keywords_lower", []) or []
    exclude_urls = mode.get("exclude_urls_lower", []) or []

    def _match(name: str = "",
               url: Optional[str] = None,
               description: Optional[str] = None,
               folder_labels: Optional[List[str]] = None) -> bool:
        url_lower = (url or "").lower()
        labels = folder_labels or []
        path_blob = " / ".join(label.lower() for label in labels if label)
        text_blob_parts = [name or ""]
        if description:
            text_blob_parts.append(description)
        if path_blob:
            text_blob_parts.append(path_blob)
        text_blob = " ".join(part.lower() for part in text_blob_parts if part)

        if exclude_urls and any(token in url_lower for token in exclude_urls):
            return False
        if exclude_keywords and any(token in text_blob for token in exclude_keywords):
            return False

        positive_checks = []
        if keywords:
            positive_checks.append(any(token in text_blob for token in keywords))
        if folder_terms:
            positive_checks.append(any(token in path_blob for token in folder_terms))
        if include_urls:
            positive_checks.append(any(token in url_lower for token in include_urls))

        if not positive_checks:
            # No positive filters defined -> accept everything unless excluded.
            return True

        return any(positive_checks)

    return _match


def _count_focus_matches(node: dict,
                         matcher,
                         parent_labels: List[str],
                         cache: Dict[str, int]) -> int:
    """
    Count the number of bookmarks within a node (recursively) that match the focus mode.
    """
    node_id = node.get("id") or "|".join(parent_labels + [node.get("name") or ""])
    if node_id in cache:
        return cache[node_id]

    node_name = node.get("name") or "(æœªå‘½åè³‡æ–™å¤¾)"
    current_labels = parent_labels + [node_name]
    total = 0

    for child in node.get("children", []) or []:
        child_type = child.get("type")
        if child_type == "url":
            url = child.get("url") or ""
            title = child.get("name") or url
            if matcher(title, url=url, folder_labels=current_labels):
                total += 1
        elif child_type == "folder":
            total += _count_focus_matches(child, matcher, current_labels, cache)

    cache[node_id] = total
    return total


_EAGLE_STATUS_CACHE = {"timestamp": 0.0, "value": False}


def is_eagle_available(force: bool = False) -> bool:
    now = time.time()
    if not force and now - _EAGLE_STATUS_CACHE["timestamp"] < 60:
        return _EAGLE_STATUS_CACHE["value"]
    try:
        response = EG.EAGLE_get_library_info()
        available = response.get("status") == "success"
    except Exception:
        available = False
    _EAGLE_STATUS_CACHE.update({"timestamp": now, "value": available})
    return available


def has_chrome_bookmarks() -> bool:
    return os.path.isfile(CHROME_BOOKMARK_PATH)


def has_db_main() -> bool:
    return os.path.isdir(DB_route_external)


_CACHE_INITIALISED = False


def _ensure_cache_setup():
    global _CACHE_INITIALISED
    if _CACHE_INITIALISED:
        return
    os.makedirs(CACHE_DATA_DIR, exist_ok=True)
    os.makedirs(THUMBNAIL_CACHE_DIR, exist_ok=True)
    conn = sqlite3.connect(THUMBNAIL_CACHE_DB)
    try:
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS media_items (
                id TEXT PRIMARY KEY,
                source TEXT NOT NULL,
                original_url TEXT,
                title TEXT,
                media_type TEXT,
                sub_type TEXT,
                metadata TEXT,
                updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
            )
            """
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS thumbnails (
                media_id TEXT PRIMARY KEY REFERENCES media_items(id) ON DELETE CASCADE,
                local_path TEXT NOT NULL,
                fetched_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                source TEXT
            )
            """
        )
        conn.execute("CREATE INDEX IF NOT EXISTS idx_media_items_source ON media_items(source)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_media_items_type ON media_items(media_type)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_media_items_url ON media_items(original_url)")
    finally:
        conn.commit()
        conn.close()
    _CACHE_INITIALISED = True


def _get_cache_connection():
    _ensure_cache_setup()
    conn = sqlite3.connect(THUMBNAIL_CACHE_DB)
    conn.row_factory = sqlite3.Row
    return conn


def _compute_media_id(source: str, identifier: str) -> str:
    base = f"{source}|{identifier}".encode("utf-8", "ignore")
    return hashlib.sha1(base).hexdigest()


def _register_media_item(media_id: str, source: str, original_url: str, title: str,
                         media_type: str, sub_type: Optional[str] = None, extra_metadata: Optional[dict] = None) -> None:
    metadata_json = json.dumps(extra_metadata, ensure_ascii=False) if extra_metadata else None
    with _get_cache_connection() as conn:
        conn.execute(
            """
            INSERT INTO media_items (id, source, original_url, title, media_type, sub_type, metadata, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(id) DO UPDATE SET
                source=excluded.source,
                original_url=excluded.original_url,
                title=excluded.title,
                media_type=excluded.media_type,
                sub_type=excluded.sub_type,
                metadata=excluded.metadata,
                updated_at=CURRENT_TIMESTAMP
            """,
            (media_id, source, original_url, title, media_type, sub_type, metadata_json)
        )
        conn.commit()


def _get_media_sub_type(media_id: str) -> Optional[str]:
    with _get_cache_connection() as conn:
        cur = conn.execute("SELECT sub_type FROM media_items WHERE id=?", (media_id,))
        row = cur.fetchone()
    return row[0] if row and row[0] else None


def _get_cached_thumbnail_route(media_id: str) -> Optional[str]:
    with _get_cache_connection() as conn:
        cur = conn.execute("SELECT local_path FROM thumbnails WHERE media_id=?", (media_id,))
        row = cur.fetchone()
    if not row:
        return None
    local_path = row[0]
    if not local_path or not os.path.isfile(local_path):
        return None
    return _build_file_route(local_path, "external")


def _infer_extension(content_type: str | None, url: str | None) -> str:
    if content_type:
        content_type = content_type.lower()
        if "jpeg" in content_type or "jpg" in content_type:
            return "jpg"
        if "png" in content_type:
            return "png"
        if "webp" in content_type:
            return "webp"
        if "gif" in content_type:
            return "gif"
    if url:
        path = urlparse(url).path
        ext = os.path.splitext(path)[1].lower().lstrip(".")
        if ext in {"jpg", "jpeg", "png", "gif", "webp"}:
            return "jpg" if ext == "jpeg" else ext
    return "jpg"


def _download_image(url: str) -> Tuple[Optional[bytes], Optional[str]]:
    if not url:
        return None, None
    try:
        resp = requests.get(
            url,
            timeout=8,
            headers=_DEFAULT_HEADERS,
            stream=True
        )
        if resp.status_code == 200 and resp.content:
            return resp.content, resp.headers.get("Content-Type")
    except requests.RequestException:
        return None, None
    return None, None


def _store_thumbnail_bytes(media_id: str, image_bytes: bytes, content_type: Optional[str],
                           source_tag: Optional[str], origin_url: Optional[str]) -> str:
    extension = _infer_extension(content_type, origin_url)
    filename = f"{media_id}.{extension}"
    os.makedirs(THUMBNAIL_CACHE_DIR, exist_ok=True)
    abs_path = os.path.abspath(os.path.join(THUMBNAIL_CACHE_DIR, filename))
    with open(abs_path, "wb") as fh:
        fh.write(image_bytes)
    with _get_cache_connection() as conn:
        conn.execute(
            """
            INSERT INTO thumbnails (media_id, local_path, fetched_at, source)
            VALUES (?, ?, CURRENT_TIMESTAMP, ?)
            ON CONFLICT(media_id) DO UPDATE SET
                local_path=excluded.local_path,
                fetched_at=CURRENT_TIMESTAMP,
                source=excluded.source
            """,
            (media_id, abs_path, source_tag)
        )
        conn.commit()
    return _build_file_route(abs_path, "external")


def _cache_thumbnail_for_bookmark(url: str, title: str, folder_info: Optional[dict] = None) -> Tuple[Optional[str], Optional[str]]:
    identifier = url or title or "bookmark"
    media_id = _compute_media_id("bookmark", identifier)
    metadata = folder_info or {}
    video_id = _extract_youtube_id(url)
    sub_type = "youtube" if video_id else None

    _register_media_item(
        media_id,
        source="bookmark",
        original_url=url,
        title=title,
        media_type="bookmark",
        sub_type=sub_type,
        extra_metadata=metadata
    )

    cached_route = _get_cached_thumbnail_route(media_id)
    if cached_route:
        return cached_route, _get_media_sub_type(media_id)

    thumbnail_url = _get_youtube_thumbnail(video_id) if video_id else None
    if not thumbnail_url:
        special_thumb = _get_special_site_thumbnail(url)
        if special_thumb:
            thumbnail_url = special_thumb
            sub_type = sub_type or "special"

    if not thumbnail_url:
        return None, sub_type

    image_bytes, content_type = _download_image(thumbnail_url)
    if not image_bytes:
        return None, sub_type

    _register_media_item(
        media_id,
        source="bookmark",
        original_url=url,
        title=title,
        media_type="bookmark",
        sub_type=sub_type,
        extra_metadata=metadata
    )

    route = _store_thumbnail_bytes(media_id, image_bytes, content_type, sub_type or "bookmark", thumbnail_url)
    return route, sub_type


def _normalize_source(src):
    return "external" if src == "external" else "internal"


def _normalize_slashes(path):
    return path.replace("\\", "/")


def _is_image_file(filename):
    return os.path.splitext(filename)[1].lower().lstrip(".") in IMAGE_EXTENSIONS


def _is_video_file(filename):
    return os.path.splitext(filename)[1].lower().lstrip(".") in VIDEO_EXTENSIONS


def _build_file_route(abs_path, src):
    normalized = _normalize_slashes(abs_path)
    if src == "external":
        return f"/serve_image/{normalized}"
    return f"/{normalized}"

def _build_image_url(rel_path, src):
    normalized_src = _normalize_source(src)
    normalized_path = _normalize_slashes(rel_path or "")
    quoted_path = quote(normalized_path, safe="/")
    query = "?src=external" if normalized_src == "external" else "?src=internal"
    if quoted_path:
        return f"/image/{quoted_path}{query}"
    return f"/image/{query}"


def _build_folder_url(rel_path, src):
    normalized_src = _normalize_source(src)
    normalized_path = _normalize_slashes(rel_path or "")
    quoted_path = quote(normalized_path, safe="/")

    if normalized_src == "external":
        return f"/both/{quoted_path}" if quoted_path else "/"

    if quoted_path:
        return f"/both/{quoted_path}/?src=internal"
    return "/?src=internal"


def _build_video_url(rel_path, src):
    normalized = _normalize_slashes(rel_path)
    quoted_path = quote(normalized, safe="/")
    query = "?src=external" if _normalize_source(src) == "external" else "?src=internal"
    return f"/video/{quoted_path}{query}"


def _find_video_thumbnail(abs_video_path, src):
    base, _ = os.path.splitext(abs_video_path)
    candidates = []
    for ext in IMAGE_EXTENSIONS:
        candidates.append(f"{base}_thumbnail.{ext}")
        candidates.append(f"{base}.{ext}")

    for candidate in candidates:
        if os.path.isfile(candidate):
            return _build_file_route(candidate, src)

    return DEFAULT_VIDEO_THUMBNAIL_ROUTE


def _find_directory_thumbnail(abs_folder_path, src):
    for root, _, files in os.walk(abs_folder_path):
        for file_name in sorted(files):
            abs_file_path = os.path.join(root, file_name)
            if _is_image_file(file_name):
                return _build_file_route(abs_file_path, src)
            if _is_video_file(file_name):
                return _find_video_thumbnail(abs_file_path, src)
    return DEFAULT_THUMBNAIL_ROUTE


def _build_folder_entry(display_name, abs_path, rel_path, src):
    return {
        "name": display_name,
        "thumbnail_route": _find_directory_thumbnail(abs_path, src),
        "url": _build_folder_url(rel_path, src),
        "item_path": os.path.abspath(abs_path),
        "media_type": "folder",
        "ext": None
    }


def _build_image_entry(display_name, abs_path, rel_path, src):
    file_route = _build_file_route(abs_path, src)
    ext = os.path.splitext(display_name)[1].lstrip(".").lower()
    return {
        "name": display_name,
        "thumbnail_route": file_route,
        "url": _build_image_url(rel_path, src),
        "item_path": os.path.abspath(abs_path),
        "media_type": "image",
        "ext": ext or None
    }


def _build_video_entry(display_name, abs_path, rel_path, src):
    ext = os.path.splitext(display_name)[1].lstrip(".").lower()
    return {
        "name": display_name,
        "thumbnail_route": _find_video_thumbnail(abs_path, src),
        "url": _build_video_url(rel_path, src),
        "item_path": os.path.abspath(abs_path),
        "media_type": "video",
        "ext": ext or None
    }


def _collect_directory_entries(base_dir, relative_path, src):
    normalized_src = _normalize_source(src)
    target_dir = os.path.join(base_dir, relative_path) if relative_path else base_dir
    if not os.path.isdir(target_dir):
        abort(404)

    try:
        entries = sorted(os.listdir(target_dir))
    except FileNotFoundError:
        abort(404)

    folders, files = [], []
    for entry in entries:
        if entry.startswith("."):
            continue
        abs_entry = os.path.join(target_dir, entry)
        rel_entry = os.path.relpath(abs_entry, base_dir)
        rel_entry = _normalize_slashes(rel_entry)

        if os.path.isdir(abs_entry):
            folders.append(_build_folder_entry(entry, abs_entry, rel_entry, normalized_src))
        elif _is_image_file(entry):
            files.append(_build_image_entry(entry, abs_entry, rel_entry, normalized_src))
        elif _is_video_file(entry):
            files.append(_build_video_entry(entry, abs_entry, rel_entry, normalized_src))

    return folders + files


def _human_readable_size(num_bytes):
    if num_bytes < 1024:
        return f"{num_bytes} B"
    units = ["KB", "MB", "GB", "TB", "PB"]
    size = float(num_bytes)
    for unit in units:
        size /= 1024.0
        if size < 1024.0 or unit == units[-1]:
            return f"{size:.2f} {unit}"

    return f"{size:.2f} PB"


def _safe_relative_path(path):
    if not path:
        return ""
    normalized = _normalize_slashes(os.path.normpath(path))
    if normalized.startswith("../") or normalized == "..":
        abort(403)
    if os.path.isabs(path):
        abort(403)
    return normalized

def get_all_folders_info(src):
    """
    å–å¾— DB_route å…§çš„æ‰€æœ‰å­è³‡æ–™å¤¾è³‡è¨Šï¼Œç¬¦åˆ EAGLE API æ ¼å¼
    src: internal or external
    """

    normalized_src = _normalize_source(src)
    base_dir = DB_route_external if normalized_src == "external" else DB_route_internal

    if not os.path.isdir(base_dir):
        abort(404)

    metadata = {
        "name": "All Collections",
        "category": "collections",
        "tags": ["collection", "group", "Main"],
        "path": "/" if normalized_src == "external" else "/?src=internal",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": os.path.abspath(base_dir)
    }

    data = _collect_directory_entries(base_dir, "", normalized_src)
    metadata["folders"] = [{
        "name": "Root",
        "url": _build_folder_url("", normalized_src)
    }]
    return metadata, data

def get_folder_images(folder_path, src=None):
    """
    å–å¾—æŒ‡å®šè³‡æ–™å¤¾å…§çš„æ‰€æœ‰åœ–ç‰‡ï¼Œç¬¦åˆ EAGLE API æ ¼å¼
    å¾žä»»æ„è³‡æ–™å¤¾ï¼ˆbase_dir + folder_pathï¼‰ä¸­å–å¾—åœ–ç‰‡
    """

    normalized_src = _normalize_source(src)
    safe_folder_path = _safe_relative_path(folder_path)
    base_dir = DB_route_external if normalized_src == "external" else DB_route_internal

    target_dir = os.path.join(base_dir, safe_folder_path) if safe_folder_path else base_dir
    if not os.path.isdir(target_dir):
        abort(404)
    
    metadata = {
        "name": os.path.basename(safe_folder_path.rstrip("/")) if safe_folder_path else os.path.basename(os.path.normpath(base_dir)),
        "category": "folder",
        "tags": [],
        "path": _build_folder_url(safe_folder_path, normalized_src),
        "thumbnail_route": _find_directory_thumbnail(target_dir, normalized_src),
        "filesystem_path": os.path.abspath(target_dir)
    }

    data = _collect_directory_entries(base_dir, safe_folder_path, normalized_src)
    return metadata, data


def get_video_details(video_path, src=None):
    """
    å–å¾—å½±ç‰‡è©³ç´°è³‡è¨Šèˆ‡æ’­æ”¾æ‰€éœ€è·¯å¾‘ã€‚
    """
    normalized_src = _normalize_source(src)
    safe_video_path = _safe_relative_path(video_path)
    base_dir = DB_route_external if normalized_src == "external" else DB_route_internal
    target_path = os.path.join(base_dir, safe_video_path) if safe_video_path else base_dir

    if not os.path.isfile(target_path) or not _is_video_file(target_path):
        abort(404)

    file_name = os.path.basename(safe_video_path) if safe_video_path else os.path.basename(target_path)
    file_ext = os.path.splitext(file_name)[1].lstrip(".").lower()
    file_size = os.path.getsize(target_path)
    modified_time = datetime.fromtimestamp(os.path.getmtime(target_path))
    thumbnail_route = _find_video_thumbnail(target_path, normalized_src)
    source_url = _build_file_route(target_path, normalized_src)
    mime_type = mimetypes.guess_type(file_name)[0] or "video/mp4"

    parent_relative = _normalize_slashes(os.path.dirname(safe_video_path))
    parent_url = _build_folder_url(parent_relative, normalized_src) if parent_relative else ("/" if normalized_src == "external" else "/?src=internal")

    folder_links = []
    if parent_relative:
        folder_links.append({
            "name": os.path.basename(parent_relative) or parent_relative,
            "url": parent_url
        })
    else:
        root_name = os.path.basename(os.path.normpath(DB_route_external if normalized_src == "external" else DB_route_internal)) or "Root"
        folder_links.append({
            "name": root_name,
            "url": parent_url
        })

    similar_items = _build_local_similar_items(target_path, base_dir, normalized_src, limit=6)

    metadata = {
        "name": file_name,
        "category": "video",
        "tags": [],
        "path": _build_video_url(safe_video_path, normalized_src),
        "thumbnail_route": thumbnail_route,
        "filesystem_path": os.path.abspath(os.path.dirname(target_path)),
        "folders": folder_links,
        "similar": similar_items,
        "ext": file_ext or None
    }

    video_data = {
        "name": file_name,
        "relative_path": safe_video_path,
        "source_url": source_url,
        "thumbnail_route": thumbnail_route,
        "original_url": None,
        "mime_type": mime_type,
        "size_bytes": file_size,
        "size_display": _human_readable_size(file_size),
        "modified_time": modified_time.strftime("%Y-%m-%d %H:%M"),
        "parent_url": parent_url,
        "download_url": source_url,
        "folders": folder_links,
        "ext": file_ext or None
    }

    return metadata, video_data


def get_image_details(image_path, src=None):
    """
    å–å¾—åœ–ç‰‡è©³ç´°è³‡è¨Šèˆ‡å±•ç¤ºæ‰€éœ€è·¯å¾‘ã€‚
    """
    normalized_src = _normalize_source(src)
    safe_image_path = _safe_relative_path(image_path)
    base_dir = DB_route_external if normalized_src == "external" else DB_route_internal
    target_path = os.path.join(base_dir, safe_image_path) if safe_image_path else base_dir

    if not os.path.isfile(target_path) or not _is_image_file(target_path):
        abort(404)

    file_name = os.path.basename(safe_image_path) if safe_image_path else os.path.basename(target_path)
    file_ext = os.path.splitext(file_name)[1].lstrip(".").lower()
    file_size = os.path.getsize(target_path)
    modified_time = datetime.fromtimestamp(os.path.getmtime(target_path))
    source_url = _build_file_route(target_path, normalized_src)
    mime_type = mimetypes.guess_type(file_name)[0] or "image/jpeg"

    parent_relative = _normalize_slashes(os.path.dirname(safe_image_path))
    parent_url = _build_folder_url(parent_relative, normalized_src) if parent_relative else ("/" if normalized_src == "external" else "/?src=internal")

    folder_links = []
    if parent_relative:
        folder_links.append({
            "name": os.path.basename(parent_relative) or parent_relative,
            "url": parent_url
        })
    else:
        root_name = os.path.basename(os.path.normpath(DB_route_external if normalized_src == "external" else DB_route_internal)) or "Root"
        folder_links.append({
            "name": root_name,
            "url": parent_url
        })

    similar_items = _build_local_similar_items(target_path, base_dir, normalized_src, limit=6)

    metadata = {
        "name": file_name,
        "category": "image",
        "tags": [],
        "path": _build_image_url(safe_image_path, normalized_src),
        "thumbnail_route": source_url,
        "filesystem_path": os.path.abspath(target_path),
        "folders": folder_links,
        "similar": similar_items,
        "ext": file_ext or None
    }

    image_data = {
        "name": file_name,
        "relative_path": safe_image_path,
        "source_url": source_url,
        "thumbnail_route": source_url,
        "original_url": None,
        "mime_type": mime_type,
        "size_bytes": file_size,
        "size_display": _human_readable_size(file_size),
        "modified_time": modified_time.strftime("%Y-%m-%d %H:%M"),
        "parent_url": parent_url,
        "download_url": source_url,
        "folders": folder_links,
        "ext": file_ext or None
    }

    return metadata, image_data

def get_eagle_folders():
    """
    ç²å– Eagle API æä¾›çš„æ‰€æœ‰è³‡æ–™å¤¾è³‡è¨Š
    """
    response = EG.EAGLE_get_library_info()
    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch Eagle folders: {response.get('data')}")

    metadata = {
        "name": "All Eagle Folders",
        "category": "collections",
        "tags": ["eagle", "folders"],
        "path": "/EAGLE_folder",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": EG.EAGLE_get_current_library_path()
    }

    data = []
    for folder in response.get("data", {}).get("folders", []):
        folder_id = folder.get("id")
        folder_name = folder.get("name", "Unnamed Folder")

        # å–å¾— Eagle è³‡æ–™å¤¾å…§çš„ç¸®åœ–
        folder_response = EG.EAGLE_list_items(folders=[folder_id])
        image_items = folder_response.get("data", [])
        image_items.sort(key=lambda x: x.get("name", ""))
        thumbnail_path = f"/serve_image/{EG.EAGLE_get_current_library_path()}/images/{image_items[0]['id']}.info/{image_items[0]['name']}.{image_items[0]['ext']}" if image_items else DEFAULT_THUMBNAIL_ROUTE

        data.append({
            "name": folder_name,
            "id": folder_id,
            "url": f"/EAGLE_folder/{folder_id}/",
            "thumbnail_route": thumbnail_path,
            "item_path": None,
            "media_type": "folder",
            "ext": None
        })

    return metadata, data

def get_eagle_images_by_folderid(eagle_folder_id):
    """
    ç²å– Eagle API æä¾›çš„æŒ‡å®šè³‡æ–™å¤¾å…§çš„åœ–ç‰‡è³‡è¨Šï¼Œç¬¦åˆ EAGLE API æ ¼å¼
    """
    response = EG.EAGLE_list_items(folders=[eagle_folder_id])
    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch images from Eagle folder: {response.get('data')}")

    # df = EG.EAGLE_get_folders_df()
    # row = df[df["id"] == eagle_folder_id]  ###ä¸¦æ²’æœ‰recursiveåœ°æ‰¾...
    # if row.empty:
    #     return []
    # folder_name = row.iloc[0]["name"]
    folder_links = []
    current_folder, parent_folder = _get_eagle_folder_context(eagle_folder_id)
    if current_folder:
        path_stack = []
        node = current_folder
        parent = parent_folder
        while parent:
            parent_id = parent.get("id")
            if parent_id:
                path_stack.append({
                    "id": parent_id,
                    "name": parent.get("name", parent_id),
                    "url": f"/EAGLE_folder/{parent_id}/"
                })
                grand = _get_eagle_folder_context(parent_id)[1]
                parent = grand
            else:
                break
        folder_links = list(reversed(path_stack))

    folder_name = current_folder.get("name") if current_folder else eagle_folder_id

    metadata = {
        "name": folder_name,
        "category": "folder",
        "tags": [],
        "path": f"/EAGLE_folder/{eagle_folder_id}",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": None,
        "folders": folder_links
    }
    image_items = response.get("data", [])
    data = _format_eagle_items(image_items)
    return metadata, data

def get_eagle_images_by_tag(target_tag):
    """
    å¾ž Eagle API ç²å–æ‰€æœ‰å¸¶æœ‰æŒ‡å®šæ¨™ç±¤çš„åœ–ç‰‡ï¼Œç¬¦åˆ EAGLE API æ ¼å¼ã€‚

    Args:
        target_tag (str): è¦æŸ¥è©¢çš„æ¨™ç±¤ã€‚

    Returns:
        (metadata, data): ä»¥ç¬¦åˆ EAGLE API æ¨£å¼çš„ `metadata` èˆ‡ `data`
    """
    # å¾ž Eagle API ç²å–å¸¶æœ‰è©²æ¨™ç±¤çš„åœ–ç‰‡
    response = EG.EAGLE_list_items(tags=[target_tag], orderBy="CREATEDATE")
    if response.get('status') == 'error':
        abort(500, description=f"Error fetching images with tag '{target_tag}': {response.get('data')}")

    # è¨­å®š metadata
    metadata = {
        "name": f"Images with Tag: {target_tag}",
        "category": "tag",
        "tags": [target_tag],
        "path": f"/EAGLE_tag/{target_tag}",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": None
    }

    image_items = response.get("data", [])
    data = _format_eagle_items(image_items)
    return metadata, data

def get_eagle_tags():
    """
    å¾ž Eagle API å–å¾—æ‰€æœ‰æ¨™ç±¤è³‡è¨Šï¼Œæ•´ç†çµ¦å‰ç«¯ä½¿ç”¨ã€‚
    """
    response = EG.EAGLE_get_tags()
    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch Eagle tags: {response.get('data')}")

    raw_data = response.get("data", [])
    if isinstance(raw_data, dict):
        tag_entries = raw_data.get("tags") or raw_data.get("data") or []
    else:
        tag_entries = raw_data or []

    tags = []
    for entry in tag_entries:
        if isinstance(entry, dict):
            tag_name = entry.get("name") or entry.get("tag") or entry.get("title")
            count_value = (
                entry.get("count")
                or entry.get("itemCount")
                or entry.get("itemsCount")
                or entry.get("childCount")
            )
        else:
            tag_name = str(entry)
            count_value = None

        if not tag_name:
            continue

        try:
            count = int(count_value) if count_value is not None else None
        except (TypeError, ValueError):
            count = None

        tags.append({
            "name": tag_name,
            "count": count
        })

    tags.sort(key=lambda item: item["name"].lower())

    metadata = {
        "name": "EAGLE Tags",
        "category": "tag-list",
        "tags": [],
        "path": "/EAGLE_tags",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": None
    }

    return metadata, tags

def search_eagle_items(keyword, limit=120):
    """é€éŽ Eagle API æœå°‹é—œéµå­—ä¸¦å›žå‚³æ ¼å¼åŒ–å¾Œçš„åˆ—è¡¨ã€‚"""
    response = EG.EAGLE_list_items(keyword=keyword, limit=limit, orderBy="CREATEDATE")
    if response.get("status") != "success":
        abort(500, description=f"Failed to search Eagle items: {response.get('data')}")

    raw_items = response.get("data", [])
    data = _format_eagle_items(raw_items)

    metadata = {
        "name": f"Search Results: {keyword}",
        "category": "search",
        "tags": [keyword],
        "path": f"/search?query={keyword}",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": EG.EAGLE_get_current_library_path()
    }

    return metadata, data

def get_eagle_stream_items(offset=0, limit=30):
    """
    å–å¾— Eagle åœ–ç‰‡/å½±ç‰‡ä¸²æµç”¨çš„é …ç›®æ¸…å–®ã€‚
    """
    try:
        response = EG.EAGLE_list_items(limit=limit, offset=offset, orderBy="CREATEDATE")
    except Exception as exc:
        abort(500, description=f"Failed to fetch Eagle stream items: {exc}")

    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch Eagle stream items: {response.get('data')}")

    raw_items = response.get("data", []) or []
    return _format_eagle_items(raw_items)


def _load_chrome_bookmarks():
    if not os.path.exists(CHROME_BOOKMARK_PATH):
        return {}
    try:
        with open(CHROME_BOOKMARK_PATH, "r", encoding="utf-8") as fh:
            return json.load(fh)
    except (json.JSONDecodeError, OSError):
        abort(500, description="Failed to read Chrome bookmarks data")


def _find_chrome_node(bookmarks_root, path_parts):
    roots = bookmarks_root.get("roots", {}) if bookmarks_root else {}
    if not path_parts:
        return None, None, None

    first = path_parts[0]
    current = roots.get(first)
    if current is None:
        abort(404)

    parent = None
    parent_path = ""
    current_path = first

    for part in path_parts[1:]:
        if current.get("type") != "folder":
            abort(404)
        next_node = None
        for child in current.get("children", []):
            if child.get("id") == part:
                next_node = child
                break
        if next_node is None:
            abort(404)
        parent = current
        parent_path = current_path
        current = next_node
        current_path = f"{current_path}/{part}"

    return current, parent, parent_path


def get_chrome_bookmarks(folder_path=None, focus_mode_id: Optional[str] = None):
    bookmarks = _load_chrome_bookmarks()
    roots = bookmarks.get("roots", {})
    safe_path = (folder_path or "bookmark_bar").strip("/")

    if not roots:
        abort(404)

    parts = [part for part in safe_path.split("/") if part]
    if not parts:
        abort(404)

    current, parent, parent_path = _find_chrome_node(bookmarks, parts)
    if current is None:
        abort(404)

    focus_config = _get_focus_mode_config()
    focus_modes: List[Dict[str, object]] = focus_config.get("modes", [])  # type: ignore[assignment]
    if not focus_modes:
        focus_modes = _sanitize_focus_config(_DEFAULT_FOCUS_CONFIG)["modes"]  # Fallback safety net

    mode_lookup = {mode["id"]: mode for mode in focus_modes}
    requested_mode = (focus_mode_id or "").strip().lower()
    default_mode_id = str(focus_config.get("default_mode") or "all").strip().lower()
    active_mode = mode_lookup.get(requested_mode) or mode_lookup.get(default_mode_id) or focus_modes[0]
    active_mode_id = active_mode["id"]
    matcher = None if active_mode_id == "all" else _build_focus_matcher(active_mode)

    query_suffix = f"?mode={quote_plus(active_mode_id)}" if active_mode_id else ""
    base_path = f"/chrome/{quote(safe_path, safe='/')}"

    breadcrumb = []
    breadcrumb_labels: List[str] = []
    path_cursor: List[str] = []

    root_node = roots.get(parts[0])
    if root_node is None:
        abort(404)

    current_node = root_node
    for idx, part in enumerate(parts):
        if idx == 0:
            node_label = root_node.get("name") or ("Bookmarks" if part == "bookmark_bar" else part)
        else:
            if current_node.get("type") != "folder":
                abort(404)
            next_node = None
            for child in current_node.get("children", []) or []:
                if child.get("id") == part:
                    next_node = child
                    break
            if next_node is None:
                abort(404)
            current_node = next_node
            node_label = current_node.get("name") or "(æœªå‘½åè³‡æ–™å¤¾)"

        path_cursor.append(part)
        breadcrumb.append({
            "name": node_label or "(æœªå‘½åè³‡æ–™å¤¾)",
            "url": f"/chrome/{quote('/'.join(path_cursor), safe='/')}{query_suffix}"
        })
        breadcrumb_labels.append(node_label or "(æœªå‘½åè³‡æ–™å¤¾)")

    current_name = current.get("name") or (breadcrumb_labels[-1] if breadcrumb_labels else "(æœªå‘½åè³‡æ–™å¤¾)")

    metadata = {
        "name": current_name,
        "category": "chrome",
        "tags": ["chrome", "bookmarks"],
        "path": base_path,
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": CHROME_BOOKMARK_PATH,
        "folders": breadcrumb
    }

    if active_mode_id != "all":
        metadata["tags"].append(f"focus:{active_mode_id}")

    children = current.get("children", []) or []
    data = []
    match_cache: Dict[str, int] = {}

    parent_labels_for_current = breadcrumb_labels[:-1] if breadcrumb_labels else []
    total_focus_matches = None
    if matcher:
        total_focus_matches = _count_focus_matches(current, matcher, parent_labels_for_current, match_cache)

    direct_bookmark_total = 0
    direct_bookmark_matches = 0

    for child in children:
        child_type = child.get("type")
        if child_type == "folder":
            child_name = child.get("name") or "(æœªå‘½åè³‡æ–™å¤¾)"
            child_id = child.get("id")
            if not child_id:
                continue
            child_path = f"{safe_path}/{child_id}"
            folder_labels = breadcrumb_labels + [child_name]
            description = None

            if matcher:
                focus_count = _count_focus_matches(child, matcher, breadcrumb_labels, match_cache)
                if focus_count <= 0:
                    continue
                description = f"{focus_count} å€‹å°ˆæ³¨æ›¸ç±¤"

            data.append({
                "name": child_name,
                "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
                "url": f"/chrome/{quote(child_path, safe='/')}{query_suffix}",
                "item_path": None,
                "media_type": "folder",
                "ext": None,
                "description": description,
                "folder_labels": folder_labels,
                "path_display": " / ".join(folder_labels)
            })
        elif child_type == "url":
            url = child.get("url")
            if not url:
                continue

            direct_bookmark_total += 1

            child_name = child.get("name") or url
            folder_labels = list(breadcrumb_labels)
            path_display = " / ".join(folder_labels)

            matches_focus = True
            if matcher:
                matches_focus = matcher(child_name, url=url, folder_labels=folder_labels, description=path_display)

            if not matches_focus:
                continue

            direct_bookmark_matches += 1

            folder_meta = {"folder_path": path_display}
            thumbnail, sub_type = _cache_thumbnail_for_bookmark(url, child_name, folder_meta)
            thumbnail = thumbnail or DEFAULT_THUMBNAIL_ROUTE

            data.append({
                "name": child_name,
                "thumbnail_route": thumbnail,
                "url": url,
                "item_path": url,
                "media_type": "bookmark",
                "ext": sub_type,
                "description": path_display or None,
                "folder_labels": folder_labels,
                "path_display": path_display
            })

    focus_options = []
    for mode in focus_modes:
        mode_id = mode["id"]
        focus_options.append({
            "id": mode_id,
            "label": mode.get("label"),
            "description": mode.get("description"),
            "is_active": mode_id == active_mode_id,
            "url": f"{base_path}?mode={quote_plus(mode_id)}"
        })

    metadata["focus_modes"] = focus_options
    metadata["focus_mode"] = {
        "id": active_mode_id,
        "label": active_mode.get("label"),
        "description": active_mode.get("description")
    }

    focus_stats = {
        "mode_id": active_mode_id,
        "mode_label": active_mode.get("label"),
        "total_bookmarks": direct_bookmark_total,
        "matched_bookmarks": direct_bookmark_matches,
        "matched_including_subfolders": total_focus_matches,
        "has_results": any(item.get("media_type") == "bookmark" for item in data)
    }
    metadata["focus_stats"] = focus_stats

    if matcher:
        summary_bits = [
            f"æœ¬å±¤ {direct_bookmark_matches} / {direct_bookmark_total} ç­†"
        ]
        if total_focus_matches is not None:
            summary_bits.append(f"å«å­å±¤ {total_focus_matches} ç­†")
        if not focus_stats["has_results"]:
            summary_bits.append("ç›®å‰æ²’æœ‰ç¬¦åˆçš„æ›¸ç±¤")
        metadata["description"] = f"ðŸŽ¯ {active_mode.get('label')} å°ˆæ³¨æ¨¡å¼ï½œ" + "ï¼Œ".join(summary_bits)

    return metadata, data


def get_chrome_youtube_bookmarks():
    bookmarks = _load_chrome_bookmarks()
    roots = bookmarks.get("roots", {})
    results = []

    def _walk(node, path_labels):
        node_type = node.get("type")
        if node_type == "folder":
            label = node.get("name") or "(æœªå‘½åè³‡æ–™å¤¾)"
            new_path = path_labels + [label]
            for child in node.get("children", []):
                _walk(child, new_path)
        elif node_type == "url":
            url = node.get("url")
            video_id = _extract_youtube_id(url)
            if not video_id:
                return
            label = node.get("name") or url
            folder_meta = {"folder_path": " / ".join(filter(None, path_labels))}
            thumbnail, sub_type = _cache_thumbnail_for_bookmark(url, label, folder_meta)
            thumbnail = thumbnail or DEFAULT_THUMBNAIL_ROUTE
            sub_type = sub_type or "youtube"
            results.append({
                "name": label,
                "thumbnail_route": thumbnail,
                "url": url,
                "item_path": url,
                "media_type": "bookmark",
                "ext": sub_type,
                "description": folder_meta.get("folder_path")
            })

    for key in ["bookmark_bar", "other", "synced", "mobile"]:
        node = roots.get(key)
        if not node:
            continue
        root_label = node.get("name") or key.replace("_", " ").title()
        _walk(node, [root_label])

    metadata = {
        "name": "YouTube æ›¸ç±¤",
        "category": "chrome-youtube",
        "tags": ["chrome", "youtube", "bookmarks"],
        "path": "/chrome_youtube/",
        "thumbnail_route": DEFAULT_THUMBNAIL_ROUTE,
        "filesystem_path": CHROME_BOOKMARK_PATH
    }

    return metadata, results

def _extract_folder_ids(raw_folders):
    """
    å°‡ Eagle å›žå‚³çš„ folder è³‡è¨Šæ•´ç†æˆ id listã€‚
    """
    if not raw_folders:
        return []

    ids = OrderedDict()

    if not isinstance(raw_folders, (list, tuple, set)):
        raw_folders = [raw_folders]

    for entry in raw_folders:
        folder_id = None
        if isinstance(entry, str):
            folder_id = entry
        elif isinstance(entry, dict):
            folder_id = (
                entry.get("id")
                or entry.get("folderId")
                or entry.get("folder_id")
            )
        if folder_id:
            folder_id = str(folder_id).strip()
            if folder_id:
                ids.setdefault(folder_id, None)

    return list(ids.keys())


def _build_eagle_folder_links(folder_ids):
    """
    å°‡ folder id è½‰æ›æˆå¯ä¾›å‰ç«¯ä½¿ç”¨çš„é€£çµè³‡è¨Šã€‚
    """
    folder_ids = _extract_folder_ids(folder_ids)
    if not folder_ids:
        return []

    try:
        df = EG.EAGLE_get_folders_df_all(flatten=True)
    except Exception:
        df = None

    lookup = {}
    if df is not None and getattr(df, "empty", True) is False:
        for _, row in df.iterrows():
            row_id = str(row.get("id") or "").strip()
            if not row_id:
                continue
            lookup[row_id] = row.get("name") or row_id

    links = []
    seen = OrderedDict()
    for folder_id in folder_ids:
        if folder_id in seen:
            continue
        seen[folder_id] = None
        folder_name = lookup.get(folder_id, folder_id)
        links.append({
            "id": folder_id,
            "name": folder_name,
            "url": f"/EAGLE_folder/{folder_id}/"
        })

    links.sort(key=lambda item: item["name"].lower())
    return links


def _normalize_item_tags(raw_tags):
    """
    å°‡ Eagle item çš„æ¨™ç±¤è½‰æ›æˆå­—ä¸² listã€‚
    """
    if not raw_tags:
        return []

    tags = OrderedDict()
    if isinstance(raw_tags, str):
        raw_tags = [raw_tags]

    for entry in raw_tags:
        tag = None
        if isinstance(entry, str):
            tag = entry
        elif isinstance(entry, dict):
            tag = entry.get("name") or entry.get("tag")
        if tag:
            normalized = tag.strip()
            if normalized:
                tags.setdefault(normalized, None)

    return list(tags.keys())


def _get_eagle_folder_context(folder_id):
    """
    å–å¾—æŒ‡å®š Eagle è³‡æ–™å¤¾åŠå…¶çˆ¶è³‡æ–™å¤¾è³‡è¨Šã€‚
    Returns (current_folder, parent_folder)
    """
    response = EG.EAGLE_get_library_info()
    if response.get("status") != "success":
        return None, None

    folders = response.get("data", {}).get("folders", [])

    def _search(nodes, parent=None):
        for node in nodes:
            if node.get("id") == folder_id:
                return node, parent
            result = _search(node.get("children", []), node)
            if result is not None:
                return result
        return None

    found = _search(folders)
    if not found:
        return None, None
    return found


def _build_local_similar_items(target_path, base_dir, src, limit=6):
    """
    æ ¹æ“šåŒè³‡æ–™å¤¾å…§å®¹æŒ‘é¸ç›¸ä¼¼çš„æœ¬åœ°é …ç›®ã€‚
    """
    parent_dir = os.path.dirname(target_path)
    try:
        entries = os.listdir(parent_dir)
    except (FileNotFoundError, PermissionError):
        return []

    candidates = []
    for entry in entries:
        if entry.startswith("."):
            continue
        abs_entry = os.path.join(parent_dir, entry)
        if abs_entry == target_path or not os.path.isfile(abs_entry):
            continue

        try:
            rel_entry = os.path.relpath(abs_entry, base_dir)
        except ValueError:
            continue
        rel_entry = _normalize_slashes(rel_entry)

        if _is_image_file(entry):
            candidates.append({
                "id": rel_entry,
                "name": os.path.splitext(entry)[0] or entry,
                "path": _build_image_url(rel_entry, src),
                "thumbnail_route": _build_file_route(abs_entry, src),
                "media_type": "image",
                "ext": os.path.splitext(entry)[1].lstrip(".").lower() or None
            })
        elif _is_video_file(entry):
            candidates.append({
                "id": rel_entry,
                "name": os.path.splitext(entry)[0] or entry,
                "path": _build_video_url(rel_entry, src),
                "thumbnail_route": _find_video_thumbnail(abs_entry, src),
                "media_type": "video",
                "ext": os.path.splitext(entry)[1].lstrip(".").lower() or None
            })

    if not candidates:
        return []

    sample_size = min(limit, len(candidates))
    if sample_size <= 0:
        return []

    return random.sample(candidates, sample_size)


def _build_eagle_similar_items(current_item_id, tags, folder_ids, limit=6):
    """
    æ ¹æ“šæ¨™ç±¤æˆ–è³‡æ–™å¤¾æŽ¨è–¦ç›¸ä¼¼é …ç›®ã€‚
    """
    candidate_map = OrderedDict()

    def _accumulate_from_response(response):
        if response.get("status") != "success":
            return
        for raw in response.get("data", []) or []:
            other_id = raw.get("id")
            if not other_id or other_id == current_item_id:
                continue
            if other_id in candidate_map:
                continue
            candidate_map[other_id] = raw

    primary_tags = tags[:2] if tags else []
    for tag in primary_tags:
        try:
            resp = EG.EAGLE_list_items(tags=[tag], limit=120, orderBy="MODIFIEDDATE")
        except Exception:
            continue
        _accumulate_from_response(resp)
        if len(candidate_map) >= limit * 2:
            break

    if not candidate_map and folder_ids:
        primary_folders = folder_ids[:2]
        for folder_id in primary_folders:
            try:
                resp = EG.EAGLE_list_items(folders=[folder_id], limit=120, orderBy="MODIFIEDDATE")
            except Exception:
                continue
            _accumulate_from_response(resp)
            if len(candidate_map) >= limit * 2:
                break

    if not candidate_map:
        return []

    candidate_list = list(candidate_map.values())
    sample_size = min(limit, len(candidate_list))
    if sample_size == 0:
        return []

    sampled_raw = random.sample(candidate_list, sample_size)
    formatted_candidates = _format_eagle_items(sampled_raw)
    formatted_map = {item["id"]: item for item in formatted_candidates if item.get("id")}

    similar_items = []
    for raw in sampled_raw:
        item_id = raw.get("id")
        formatted = formatted_map.get(item_id)
        if not formatted:
            continue
        media_type = formatted.get("media_type")
        detail_path = f"/EAGLE_video/{item_id}/" if media_type == "video" else f"/EAGLE_image/{item_id}/"
        similar_items.append({
            "id": item_id,
            "name": formatted.get("name") or "Untitled",
            "path": detail_path,
            "thumbnail_route": formatted.get("thumbnail_route") or DEFAULT_THUMBNAIL_ROUTE,
            "media_type": media_type,
            "ext": formatted.get("ext")
        })

    return similar_items


def get_eagle_video_details(item_id):
    """
    å¾ž Eagle API å–å¾—å–®ä¸€å½±ç‰‡é …ç›®çš„è©³ç´°è³‡è¨Šä¸¦çµ„åˆæˆæ’­æ”¾å™¨é é¢éœ€è¦çš„çµæ§‹ã€‚
    """
    response = EG.EAGLE_get_item_info(item_id)
    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch Eagle item info: {response.get('data')}")

    item = response.get("data")
    if not item or isinstance(item, list):
        abort(404, description="Video item not found.")

    raw_ext = item.get("ext") or ""
    ext = raw_ext.lower().lstrip(".")
    file_name = item.get("name") or item_id
    file_name_with_ext = item.get("fileName")

    if not ext and file_name_with_ext:
        _, inferred_ext = os.path.splitext(file_name_with_ext)
        ext = inferred_ext.lower().lstrip(".")

    if ext not in VIDEO_EXTENSIONS:
        abort(404, description="Requested Eagle item is not a video.")

    base_library_path = EG.EAGLE_get_current_library_path()
    item_dir = os.path.join(base_library_path, "images", f"{item_id}.info")

    candidate_files = []
    if file_name:
        candidate_files.append(f"{file_name}.{ext}")
    if file_name_with_ext:
        candidate_files.append(file_name_with_ext)
    candidate_files.append(f"{item_id}.{ext}")

    video_path = None
    for candidate in candidate_files:
        candidate_path = os.path.join(item_dir, candidate)
        if os.path.isfile(candidate_path):
            video_path = candidate_path
            break

    if video_path is None and os.path.isdir(item_dir):
        for entry in os.listdir(item_dir):
            if _is_video_file(entry):
                video_path = os.path.join(item_dir, entry)
                file_name, ext = os.path.splitext(entry)
                ext = ext.lstrip(".").lower()
                break

    if video_path is None:
        abort(404, description="Video file not found on disk.")

    normalized_abs_path = _normalize_slashes(os.path.abspath(video_path))
    relative_path = _normalize_slashes(os.path.relpath(video_path, base_library_path))
    file_size = os.path.getsize(video_path)
    modified_time = datetime.fromtimestamp(os.path.getmtime(video_path))

    stream_route = f"/serve_image/{normalized_abs_path}"

    thumbnail_route = DEFAULT_VIDEO_THUMBNAIL_ROUTE
    if os.path.isdir(item_dir):
        stem = os.path.splitext(os.path.basename(video_path))[0]
        for image_ext in IMAGE_EXTENSIONS:
            candidate_thumb = os.path.join(item_dir, f"{stem}_thumbnail.{image_ext}")
            if os.path.isfile(candidate_thumb):
                thumbnail_route = f"/serve_image/{_normalize_slashes(os.path.abspath(candidate_thumb))}"
                break

    tags = item.get("tags") or []
    tags = _normalize_item_tags(tags)

    original_url = item.get("website") or item.get("url")
    folder_ids = _extract_folder_ids(item.get("folders"))
    fallback_folder = item.get("folderId") or item.get("folder_id")
    if not folder_ids and fallback_folder:
        folder_ids = _extract_folder_ids([fallback_folder])
    folder_links = _build_eagle_folder_links(folder_ids)
    similar_items = _build_eagle_similar_items(item_id, tags, folder_ids)
    resolved_ext = ext or os.path.splitext(video_path)[1].lstrip(".").lower() or None

    metadata = {
        "name": item.get("name") or os.path.basename(video_path),
        "category": "eagle-video",
        "tags": tags,
        "path": f"/EAGLE_video/{item_id}/",
        "thumbnail_route": thumbnail_route,
        "filesystem_path": normalized_abs_path,
        "description": item.get("annotation") or item.get("note"),
        "folders": folder_links,
        "similar": similar_items,
        "ext": resolved_ext
    }

    video_data = {
        "name": metadata["name"],
        "relative_path": relative_path,
        "source_url": stream_route,
        "original_url": original_url,
        "thumbnail_route": thumbnail_route,
        "mime_type": mimetypes.guess_type(video_path)[0] or "video/mp4",
        "size_bytes": file_size,
        "size_display": _human_readable_size(file_size),
        "modified_time": modified_time.strftime("%Y-%m-%d %H:%M"),
        "parent_url": None,
        "download_url": stream_route,
        "folders": folder_links,
        "ext": resolved_ext
    }

    return metadata, video_data

def get_eagle_image_details(item_id):
    """
    å¾ž Eagle API å–å¾—å–®ä¸€åœ–ç‰‡é …ç›®çš„è©³ç´°è³‡è¨Šä¸¦çµ„åˆæˆå±•ç¤ºé é¢éœ€è¦çš„çµæ§‹ã€‚
    """
    response = EG.EAGLE_get_item_info(item_id)
    if response.get("status") != "success":
        abort(500, description=f"Failed to fetch Eagle item info: {response.get('data')}")

    item = response.get("data")
    if not item or isinstance(item, list):
        abort(404, description="Image item not found.")

    raw_ext = item.get("ext") or ""
    ext = raw_ext.lower().lstrip(".")
    file_name = item.get("name") or item_id
    file_name_with_ext = item.get("fileName")

    base_library_path = EG.EAGLE_get_current_library_path()
    item_dir = os.path.join(base_library_path, "images", f"{item_id}.info")

    candidate_files = []
    if file_name_with_ext:
        candidate_files.append(file_name_with_ext)
    if file_name:
        candidate_files.append(f"{file_name}.{ext}" if ext else file_name)
    candidate_files.append(f"{item_id}.{ext}" if ext else item_id)

    image_path = None
    resolved_ext = ext
    for candidate in candidate_files:
        if not candidate:
            continue
        candidate_path = os.path.join(item_dir, candidate)
        if os.path.isfile(candidate_path):
            resolved_ext = os.path.splitext(candidate)[1].lstrip(".").lower()
            if resolved_ext in IMAGE_EXTENSIONS:
                image_path = candidate_path
                break

    if image_path is None and os.path.isdir(item_dir):
        for entry in os.listdir(item_dir):
            entry_ext = os.path.splitext(entry)[1].lstrip(".").lower()
            if entry_ext in IMAGE_EXTENSIONS:
                image_path = os.path.join(item_dir, entry)
                resolved_ext = entry_ext
                break

    if image_path is None:
        abort(404, description="Image file not found on disk.")

    normalized_abs_path = _normalize_slashes(os.path.abspath(image_path))
    relative_path = _normalize_slashes(os.path.relpath(image_path, base_library_path))
    file_size = os.path.getsize(image_path)
    modified_time = datetime.fromtimestamp(os.path.getmtime(image_path))

    stream_route = f"/serve_image/{normalized_abs_path}"

    tags = _normalize_item_tags(item.get("tags"))
    original_url = item.get("website") or item.get("url")
    folder_ids = _extract_folder_ids(item.get("folders"))
    fallback_folder = item.get("folderId") or item.get("folder_id")
    if not folder_ids and fallback_folder:
        folder_ids = _extract_folder_ids([fallback_folder])
    folder_links = _build_eagle_folder_links(folder_ids)
    similar_items = _build_eagle_similar_items(item_id, tags, folder_ids)

    metadata = {
        "name": item.get("name") or os.path.basename(image_path),
        "category": "eagle-image",
        "tags": tags,
        "path": f"/EAGLE_image/{item_id}/",
        "thumbnail_route": stream_route,
        "filesystem_path": normalized_abs_path,
        "description": item.get("annotation") or item.get("note"),
        "folders": folder_links,
        "similar": similar_items,
        "ext": resolved_ext or None
    }

    image_data = {
        "name": metadata["name"],
        "relative_path": relative_path,
        "source_url": stream_route,
        "original_url": original_url,
        "thumbnail_route": stream_route,
        "mime_type": mimetypes.guess_type(image_path)[0] or f"image/{resolved_ext or 'jpeg'}",
        "size_bytes": file_size,
        "size_display": _human_readable_size(file_size),
        "modified_time": modified_time.strftime("%Y-%m-%d %H:%M"),
        "parent_url": None,
        "download_url": stream_route,
        "folders": folder_links,
        "ext": resolved_ext or None
    }

    return metadata, image_data

def _format_eagle_items(image_items):
    """
    å°‡ Eagle åœ–ç‰‡æ¸…å–®æ ¼å¼åŒ–æˆ EAGLE API æ¨£å¼çš„ data listã€‚
    """
    image_items.sort(key=lambda x: x.get("name", "")) # æŒ‰åç¨±æŽ’åº
    data = []

    base = EG.EAGLE_get_current_library_path()
    for image in image_items:
        image_id = image.get("id")
        image_name = image.get("name", "unknown")
        image_ext = image.get("ext", "jpg")
        image_path = f"/serve_image/{base}/images/{image_id}.info/{image_name}.{image_ext}"

        # ç‰¹åˆ¥è™•ç†å½±ç‰‡ç¸®åœ–
        normalized_ext = (image_ext or "").lower()
        is_video = normalized_ext in VIDEO_EXTENSIONS
        if normalized_ext == "mp4":
            thumbnail_route = f"/serve_image/{base}/images/{image_id}.info/{image_name}_thumbnail.png"
        else:
            thumbnail_route = image_path

        data.append({
            "id": image_id,
            "name": image_name,
            "url": image_path,
            "thumbnail_route": thumbnail_route,
            "item_path": os.path.abspath(os.path.join(base, "images", f"{image_id}.info", f"{image_name}.{image_ext}")),
            "media_type": "video" if is_video else "image",
            "ext": normalized_ext or None
        })

    return data

def get_subfolders_info(folder_id):
    """
    æ ¹æ“šæŒ‡å®šçš„ folder_idï¼Œå–å‡ºå…¶ childrenï¼ˆå­è³‡æ–™å¤¾ id listï¼‰ï¼Œ
    ä¸¦çµ„æˆç¬¦åˆå‰ç«¯å±•ç¤ºæ ¼å¼çš„ list of dictã€‚
    """
    df = EG.EAGLE_get_folders_df()

    # æ‰¾å‡ºæŒ‡å®š folder row
    row = df[df["id"] == folder_id]
    if row.empty:
        return []

    children_infos = row.iloc[0]["children"]  # æ˜¯ list
    result = []

    for child_info in children_infos:
        child_id = child_info["id"]
        # child_row = df[df["id"] == child_info["id"]]
        # if child_row.empty:
            # continue

        # child = child_row.iloc[0]
        sub_name = child_info.get("name", f"(unnamed-{child_id})")
        path = f"/EAGLE_folder/{child_id}"

        # å˜—è©¦å–ä¸€å¼µåœ–ä½œç‚ºç¸®åœ–
        folder_response = EG.EAGLE_list_items(folders=[child_id])
        thumbnail_route = DEFAULT_THUMBNAIL_ROUTE
        if folder_response.get("status") == "success" and folder_response.get("data"):
            first_img = folder_response["data"][0]
            image_id = first_img["id"]
            image_name = first_img["name"]
            image_ext = first_img["ext"]
            base = EG.EAGLE_get_current_library_path()
            thumbnail_route = f"/serve_image/{base}/images/{image_id}.info/{image_name}.{image_ext}"

        result.append({
            "name": f"ðŸ“ {sub_name}",
            "url": path,
            "thumbnail_route": thumbnail_route,
            "item_path": None,
            "media_type": "folder",
            "ext": None
        })

    return result
